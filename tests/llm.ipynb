{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup(run once)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install pip dependencies \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/site-packages (0.4.8)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/site-packages (0.0.281)\n",
      "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/site-packages (0.10.12)\n",
      "Requirement already satisfied: tdqm in /usr/local/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/site-packages (from tiktoken) (2023.8.8)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/lib/python3.10/site-packages (from chromadb) (1.10.12)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.2 in /usr/local/lib/python3.10/site-packages (from chromadb) (0.7.2)\n",
      "Requirement already satisfied: fastapi<0.100.0,>=0.95.2 in /usr/local/lib/python3.10/site-packages (from chromadb) (0.99.1)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/site-packages (from chromadb) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/site-packages (from chromadb) (1.24.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/site-packages (from chromadb) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/site-packages (from chromadb) (4.7.1)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/site-packages (from chromadb) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/site-packages (from chromadb) (1.15.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/site-packages (from chromadb) (0.13.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/site-packages (from langchain) (2.0.20)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /usr/local/lib/python3.10/site-packages (from langchain) (0.0.33)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/site-packages (from langchain) (2.8.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.10/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in /usr/local/lib/python3.10/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/site-packages (from unstructured) (4.9.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.10/site-packages (from unstructured) (2.8.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/site-packages (from fastapi<0.100.0,>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.24.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (4.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai tiktoken chromadb langchain unstructured tdqm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Output*\n",
    "\n",
    "Requirement already satisfied: openai in /usr/local/lib/python3.10/site-packages (0.28.0)\n",
    "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/site-packages (0.4.0)\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured[all-docs] in /usr/local/lib/python3.10/site-packages (0.10.12)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (5.2.0)\n",
      "Requirement already satisfied: filetype in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (0.4.27)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (4.9.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (0.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (4.12.2)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (2.8.0)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (0.5.14)\n",
      "Requirement already satisfied: msg-parser in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (3.1.2)\n",
      "Requirement already satisfied: ebooklib in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (0.18)\n",
      "Requirement already satisfied: pypandoc in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (1.11)\n",
      "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (0.8.11)\n",
      "Requirement already satisfied: python-pptx<=0.6.21 in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (0.6.21)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (2.1.0)\n",
      "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (20221105)\n",
      "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (1.16.3)\n",
      "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (2.0.1)\n",
      "Requirement already satisfied: unstructured-inference in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (0.5.22)\n",
      "Requirement already satisfied: markdown in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (3.4.4)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/site-packages (from python-pptx<=0.6.21->unstructured[all-docs]) (9.4.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/site-packages (from python-pptx<=0.6.21->unstructured[all-docs]) (3.1.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/site-packages (from beautifulsoup4->unstructured[all-docs]) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json->unstructured[all-docs]) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json->unstructured[all-docs]) (0.9.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from ebooklib->unstructured[all-docs]) (1.16.0)\n",
      "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.10/site-packages (from msg-parser->unstructured[all-docs]) (0.46)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk->unstructured[all-docs]) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk->unstructured[all-docs]) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk->unstructured[all-docs]) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk->unstructured[all-docs]) (4.66.1)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/site-packages (from openpyxl->unstructured[all-docs]) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/site-packages (from pandas->unstructured[all-docs]) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->unstructured[all-docs]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->unstructured[all-docs]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas->unstructured[all-docs]) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/site-packages (from pdfminer.six->unstructured[all-docs]) (3.2.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/site-packages (from pdfminer.six->unstructured[all-docs]) (41.0.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->unstructured[all-docs]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->unstructured[all-docs]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->unstructured[all-docs]) (2023.7.22)\n",
      "Requirement already satisfied: layoutparser[layoutmodels,tesseract] in /usr/local/lib/python3.10/site-packages (from unstructured-inference->unstructured[all-docs]) (0.3.4)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/site-packages (from unstructured-inference->unstructured[all-docs]) (0.0.6)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/site-packages (from unstructured-inference->unstructured[all-docs]) (0.16.4)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/site-packages (from unstructured-inference->unstructured[all-docs]) (4.8.0.76)\n",
      "Requirement already satisfied: onnx==1.14.1 in /usr/local/lib/python3.10/site-packages (from unstructured-inference->unstructured[all-docs]) (1.14.1)\n",
      "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/site-packages (from unstructured-inference->unstructured[all-docs]) (1.15.1)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/site-packages (from unstructured-inference->unstructured[all-docs]) (4.33.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/site-packages (from onnx==1.14.1->unstructured-inference->unstructured[all-docs]) (4.24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/site-packages (from onnx==1.14.1->unstructured-inference->unstructured[all-docs]) (4.7.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (1.15.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured[all-docs]) (23.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference->unstructured[all-docs]) (3.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference->unstructured[all-docs]) (6.0.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference->unstructured[all-docs]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference->unstructured[all-docs]) (0.3.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from huggingface-hub->unstructured-inference->unstructured[all-docs]) (2023.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[all-docs]) (1.0.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (1.11.2)\n",
      "Requirement already satisfied: iopath in /usr/local/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (0.1.10)\n",
      "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (0.10.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (0.15.2)\n",
      "Requirement already satisfied: effdet in /usr/local/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (0.4.1)\n",
      "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (0.3.10)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/site-packages (from onnxruntime->unstructured-inference->unstructured[all-docs]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/site-packages (from onnxruntime->unstructured-inference->unstructured[all-docs]) (23.5.26)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from onnxruntime->unstructured-inference->unstructured[all-docs]) (1.12)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (2.21)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/site-packages (from coloredlogs->onnxruntime->unstructured-inference->unstructured[all-docs]) (10.0)\n",
      "Requirement already satisfied: timm>=0.9.2 in /usr/local/lib/python3.10/site-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (0.9.7)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/site-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (2.0.7)\n",
      "Requirement already satisfied: omegaconf>=2.0 in /usr/local/lib/python3.10/site-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (2.3.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (3.1.2)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/site-packages (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (2.7.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/site-packages (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (4.19.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->onnxruntime->unstructured-inference->unstructured[all-docs]) (1.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/site-packages (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (4.9.3)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/site-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (3.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (1.4.5)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Output*\n",
    "\n",
    "Requirement already satisfied: unstructured[all-docs] in /usr/local/lib/python3.10/site-packages (0.10.12)\n",
    "Requirement already satisfied: chardet in /usr/local/lib/python3.10/site-packages (from unstructured[all-docs]) (5.2.0)\n",
    "\n",
    "...\n",
    "\n",
    "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (1.4.5)\n",
    "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (3.0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -U nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Output*\n",
    "\n",
    "Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (3.8.1)\n",
    "Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
    "Requirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
    "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2023.8.8)\n",
    "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.66.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/felg/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*DONE with Setup(run once)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup(run every time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load creds.env file\n",
    "\n",
    "The file 'creds.env' needs to have a line 'OPENAI_API_KEY=...'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv('creds.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Output*\n",
    "\n",
    "True \n",
    "\n",
    "    Loaded .env file, \n",
    "\n",
    "False \n",
    "    \n",
    "    fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "In the RI-HEVNAA architecture, Accelerators are specialized components within each SuperUnit that handle specific operations. Each Accelerator is tailored to the requirements of the SuperUnit it resides in. For example, the Linguistic Processing Accelerator (LP_A) in the LH_SU handles language and speech-related tasks using llms, while the Visual and Spatial Processing Accelerator (VSP_A) in the RH_SU performs spatial and visual-related tasks using yolo image models.\n",
    "\n",
    "The required functionality for Accelerators in RI_HEVNAA that you will need to consider includes:\n",
    "\n",
    "1. **Specific Operation Handling**: Each Accelerator is designed to handle specific operations relevant to the SuperUnit it is in. For instance, the System Parameter Regulator Accelerator (SPR_A) manages low-complexity signals across the system, and the State Control Accelerator (SC_A) oversees the overall system state.\n",
    "\n",
    "2. **Task Execution**: Accelerators execute Tasks within their respective SuperUnits. For example, in a language processing scenario, the Linguistic Processing Accelerator (LP_A) would execute tasks such as part-of-speech tagging, sentiment analysis, or named entity recognition.\n",
    "\n",
    "3. **Hardware Interaction**: Some Accelerators, like the Motor Coordination Accelerator (MC_A), interface with hardware components to control physical movements. This real-time hardware interaction capability allows the chatbot to interact with and respond to the physical environment in real-time.\n",
    "\n",
    "4. **Data Flow Management**: Accelerators facilitate the flow of data within the architecture. They process user inputs, analyze information, and generate meaningful responses.\n",
    "\n",
    "Remember that the Accelerators need to be designed in a way that they can be executed within the architecture, as indicated by the log messages denoting \"@Accelerators.execute\".\n",
    "\n",
    "Help me draft a new Accelerators.py file\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo_path: /Library/Github/RI-HEVNAA\n",
      "Found 29 python documents.\n",
      "Found 5 markdown documents.\n",
      "Found 7 log documents.\n",
      "Can you assist me in drafting a new Accelerators.py file for the RI_HEVNAA architecture?Sure, here's a basic template for an `Accelerators.py` file for the RI_HEVNAA architecture. This draft assumes that there will be custom classes for each of the Accelerators mentioned in the context. If not, the `load_accelerators` function and the `Accelerators` initialization may need to be adjusted accordingly.\n",
      "\n",
      "```python\n",
      "import logging\n",
      "import json\n",
      "import os\n",
      "\n",
      "# Import your custom Accelerator classes here\n",
      "# from accelerators import SPR_A, SC_A, LP_A, VSP_A, MC_A\n",
      "\n",
      "class Accelerators:\n",
      "    def __init__(self):\n",
      "        self.execute_enabled = True\n",
      "        self.accelerators = []\n",
      "        self.logger = self.init_logger()\n",
      "\n",
      "    def init_logger(self):\n",
      "        # Create logger\n",
      "        logger = logging.getLogger('Accelerators')\n",
      "        logger.setLevel(logging.DEBUG)\n",
      "\n",
      "        # Create file handler which logs even debug messages\n",
      "        fh = logging.FileHandler('logs/Accelerators.log')\n",
      "        fh.setLevel(logging.DEBUG)\n",
      "\n",
      "        # Create console handler with a higher log level\n",
      "        ch = logging.StreamHandler()\n",
      "        ch.setLevel(logging.ERROR)\n",
      "\n",
      "        # Create formatter and add it to the handlers\n",
      "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
      "        fh.setFormatter(formatter)\n",
      "        ch.setFormatter(formatter)\n",
      "\n",
      "        # Add the handlers to logger\n",
      "        logger.addHandler(fh)\n",
      "        logger.addHandler(ch)\n",
      "        \n",
      "        return logger\n",
      "\n",
      "    def load_accelerators(self, folder_path):\n",
      "        # Load JSON files with accelerator information in A_CPU/accelerators folder\n",
      "        # This assumes that the JSON files contain necessary parameters for each accelerator\n",
      "\n",
      "        # For each file in the directory\n",
      "        for filename in os.listdir(folder_path):\n",
      "            if filename.endswith('.json'):\n",
      "                with open(os.path.join(folder_path, filename)) as f:\n",
      "                    data = json.load(f)\n",
      "\n",
      "                # Create an instance of the Accelerator using the data from the JSON file\n",
      "                # This will depend on how your Accelerator classes are structured\n",
      "                # accel = YourAcceleratorClass(data)\n",
      "                # self.accelerators.append(accel)\n",
      "                \n",
      "    async def execute(self):\n",
      "        print(\"@Accelerators.execute: Start\")\n",
      "\n",
      "        self.logger.info(f\"@Accelerators.execute: Starting Execution\")\n",
      "        \n",
      "        self.load_accelerators(\"accelerators\")\n",
      "\n",
      "        # Add execution logic for your accelerators here\n",
      "```\n",
      "Please replace \"YourAcceleratorClass\" with the actual classes for your accelerators, and add the necessary logic to the `execute` function.\n",
      "The human provides a detailed description of the role of Accelerators in the RI-HEVNAA architecture, explaining that they handle specific operations within each SuperUnit. The human highlights the functionality of Accelerators, such as specific operation handling, task execution, hardware interaction, and data flow management. The human then asks the AI to help in drafting a new Accelerators.py file. In response, the AI provides a basic Python template for an `Accelerators.py` file for the RI_HEVNAA architecture, with explanations and placeholders for the human to fill in.Sure, here's a basic template for an `Accelerators.py` file for the RI_HEVNAA architecture. This draft assumes that there will be custom classes for each of the Accelerators mentioned in the context. If not, the `load_accelerators` function and the `Accelerators` initialization may need to be adjusted accordingly.\n",
      "\n",
      "```python\n",
      "import logging\n",
      "import json\n",
      "import os\n",
      "\n",
      "# Import your custom Accelerator classes here\n",
      "# from accelerators import SPR_A, SC_A, LP_A, VSP_A, MC_A\n",
      "\n",
      "class Accelerators:\n",
      "    def __init__(self):\n",
      "        self.execute_enabled = True\n",
      "        self.accelerators = []\n",
      "        self.logger = self.init_logger()\n",
      "\n",
      "    def init_logger(self):\n",
      "        # Create logger\n",
      "        logger = logging.getLogger('Accelerators')\n",
      "        logger.setLevel(logging.DEBUG)\n",
      "\n",
      "        # Create file handler which logs even debug messages\n",
      "        fh = logging.FileHandler('logs/Accelerators.log')\n",
      "        fh.setLevel(logging.DEBUG)\n",
      "\n",
      "        # Create console handler with a higher log level\n",
      "        ch = logging.StreamHandler()\n",
      "        ch.setLevel(logging.ERROR)\n",
      "\n",
      "        # Create formatter and add it to the handlers\n",
      "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
      "        fh.setFormatter(formatter)\n",
      "        ch.setFormatter(formatter)\n",
      "\n",
      "        # Add the handlers to logger\n",
      "        logger.addHandler(fh)\n",
      "        logger.addHandler(ch)\n",
      "        \n",
      "        return logger\n",
      "\n",
      "    def load_accelerators(self, folder_path):\n",
      "        # Load JSON files with accelerator information in A_CPU/accelerators folder\n",
      "        # This assumes that the JSON files contain necessary parameters for each accelerator\n",
      "\n",
      "        # For each file in the directory\n",
      "        for filename in os.listdir(folder_path):\n",
      "            if filename.endswith('.json'):\n",
      "                with open(os.path.join(folder_path, filename)) as f:\n",
      "                    data = json.load(f)\n",
      "\n",
      "                # Create an instance of the Accelerator using the data from the JSON file\n",
      "                # This will depend on how your Accelerator classes are structured\n",
      "                # accel = YourAcceleratorClass(data)\n",
      "                # self.accelerators.append(accel)\n",
      "                \n",
      "    async def execute(self):\n",
      "        print(\"@Accelerators.execute: Start\")\n",
      "\n",
      "        self.logger.info(f\"@Accelerators.execute: Starting Execution\")\n",
      "        \n",
      "        self.load_accelerators(\"accelerators\")\n",
      "\n",
      "        # Add execution logic for your accelerators here\n",
      "```\n",
      "Please replace \"YourAcceleratorClass\" with the actual classes for your accelerators, and add the necessary logic to the `execute` function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute 'llm_repo_feedback_V0.py' with command line arguments: --prompt=question\n",
    "\n",
    "# use python 3.10.12 to run script\n",
    "\n",
    "#prepare command to be run in terminal\n",
    "command = \"python3.10 programs/llm_repo_feedback_V0.py --prompt='\" + question + \"'\"\n",
    "\n",
    "#run command in terminal\n",
    "!{command}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load repo_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo_path: /Library/Github/RI-HEVNAA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "repo_path = working_dir\n",
    "\n",
    "print(f\"repo_path: {repo_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "\n",
    "def load_documents(repo_path, type):\n",
    "    loader = GenericLoader.from_filesystem(\n",
    "        repo_path,\n",
    "        glob=f\"**/**/*\",\n",
    "        suffixes=[type],\n",
    "        parser=LanguageParser()\n",
    "    )\n",
    "\n",
    "    new_documents = loader.load()\n",
    "\n",
    "    print(f\"Found {len(new_documents)} documents.\")\n",
    "    for new_document in new_documents:\n",
    "        print(f\"Document: {new_document.metadata}\")\n",
    "    \n",
    "    return new_documents\n",
    "\n",
    "documents = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 documents.\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/RIHEVNAA.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/RIHEVNAA.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/RIHEVNAA.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/RIHEVNAA.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/BusManager.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/BusManager.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/test.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/HCPU.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/HCPU.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/WebMonitoringProcess.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/WebMonitoringProcess.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/Unit.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/Unit.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/main.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/main.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/Accelerators.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/Accelerators.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/ControlUnit.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/ControlUnit.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/ExecutionUnit.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/ExecutionUnit.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/MemoryUnit.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/MemoryUnit.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/programs/print_string.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/programs/print_string.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n"
     ]
    }
   ],
   "source": [
    "python_documents = load_documents(repo_path, \".py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 documents.\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/README.md'}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/CHANGELOG.md'}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/docs/FAQ.md'}\n"
     ]
    }
   ],
   "source": [
    "markdown_documents = load_documents(repo_path, \".md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 documents.\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/logs/A_HCPU.log'}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/logs/BusManager.log'}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/logs/R_HCPU.log'}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/logs/L_HCPU.log'}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/logs/WebMonitoringProcess.log'}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/logs/execute.log'}\n",
      "Document: {'source': '/Library/Github/RI-HEVNAA/logs/Accelerators.log'}\n"
     ]
    }
   ],
   "source": [
    "log_documents = load_documents(repo_path, \".log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 python documents.\n",
      "Found 5 markdown documents.\n",
      "Found 7 log documents.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Found {len(python_documents)} python documents.\")\n",
    "print(f\"Found {len(markdown_documents)} markdown documents.\")\n",
    "print(f\"Found {len(log_documents)} log documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 99 texts.\n",
      "1:{'source': '/Library/Github/RI-HEVNAA/RIHEVNAA.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "2:{'source': '/Library/Github/RI-HEVNAA/RIHEVNAA.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "3:{'source': '/Library/Github/RI-HEVNAA/RIHEVNAA.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "4:{'source': '/Library/Github/RI-HEVNAA/RIHEVNAA.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "5:{'source': '/Library/Github/RI-HEVNAA/RIHEVNAA.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "6:{'source': '/Library/Github/RI-HEVNAA/BusManager.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "7:{'source': '/Library/Github/RI-HEVNAA/BusManager.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "8:{'source': '/Library/Github/RI-HEVNAA/test.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "9:{'source': '/Library/Github/RI-HEVNAA/HCPU.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "10:{'source': '/Library/Github/RI-HEVNAA/HCPU.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "11:{'source': '/Library/Github/RI-HEVNAA/HCPU.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "12:{'source': '/Library/Github/RI-HEVNAA/WebMonitoringProcess.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "13:{'source': '/Library/Github/RI-HEVNAA/WebMonitoringProcess.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "14:{'source': '/Library/Github/RI-HEVNAA/Unit.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "15:{'source': '/Library/Github/RI-HEVNAA/Unit.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "16:{'source': '/Library/Github/RI-HEVNAA/main.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "17:{'source': '/Library/Github/RI-HEVNAA/main.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "18:{'source': '/Library/Github/RI-HEVNAA/Accelerators.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "19:{'source': '/Library/Github/RI-HEVNAA/Accelerators.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "20:{'source': '/Library/Github/RI-HEVNAA/Accelerators.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "21:{'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/ControlUnit.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "22:{'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/ControlUnit.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "23:{'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/ControlUnit.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "24:{'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/ExecutionUnit.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "25:{'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/ExecutionUnit.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "26:{'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/MemoryUnit.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "27:{'source': '/Library/Github/RI-HEVNAA/HCPU_Sub_Components/MemoryUnit.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "28:{'source': '/Library/Github/RI-HEVNAA/programs/print_string.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
      "29:{'source': '/Library/Github/RI-HEVNAA/programs/print_string.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
      "30:{'source': '/Library/Github/RI-HEVNAA/README.md'}\n",
      "31:{'source': '/Library/Github/RI-HEVNAA/README.md'}\n",
      "32:{'source': '/Library/Github/RI-HEVNAA/README.md'}\n",
      "33:{'source': '/Library/Github/RI-HEVNAA/README.md'}\n",
      "34:{'source': '/Library/Github/RI-HEVNAA/README.md'}\n",
      "35:{'source': '/Library/Github/RI-HEVNAA/README.md'}\n",
      "36:{'source': '/Library/Github/RI-HEVNAA/README.md'}\n",
      "37:{'source': '/Library/Github/RI-HEVNAA/README.md'}\n",
      "38:{'source': '/Library/Github/RI-HEVNAA/README.md'}\n",
      "39:{'source': '/Library/Github/RI-HEVNAA/README.md'}\n",
      "40:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/CHANGELOG.md'}\n",
      "41:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/CHANGELOG.md'}\n",
      "42:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/CHANGELOG.md'}\n",
      "43:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/CHANGELOG.md'}\n",
      "44:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/CHANGELOG.md'}\n",
      "45:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/CHANGELOG.md'}\n",
      "46:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/CHANGELOG.md'}\n",
      "47:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/CHANGELOG.md'}\n",
      "48:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "49:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "50:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "51:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "52:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "53:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "54:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "55:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "56:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "57:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "58:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "59:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "60:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "61:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README.md'}\n",
      "62:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "63:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "64:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "65:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "66:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "67:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "68:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "69:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "70:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "71:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "72:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "73:{'source': '/Library/Github/RI-HEVNAA/node_modules/dotenv/README-es.md'}\n",
      "74:{'source': '/Library/Github/RI-HEVNAA/logs/A_HCPU.log'}\n",
      "75:{'source': '/Library/Github/RI-HEVNAA/logs/A_HCPU.log'}\n",
      "76:{'source': '/Library/Github/RI-HEVNAA/logs/A_HCPU.log'}\n",
      "77:{'source': '/Library/Github/RI-HEVNAA/logs/A_HCPU.log'}\n",
      "78:{'source': '/Library/Github/RI-HEVNAA/logs/A_HCPU.log'}\n",
      "79:{'source': '/Library/Github/RI-HEVNAA/logs/A_HCPU.log'}\n",
      "80:{'source': '/Library/Github/RI-HEVNAA/logs/A_HCPU.log'}\n",
      "81:{'source': '/Library/Github/RI-HEVNAA/logs/BusManager.log'}\n",
      "82:{'source': '/Library/Github/RI-HEVNAA/logs/R_HCPU.log'}\n",
      "83:{'source': '/Library/Github/RI-HEVNAA/logs/R_HCPU.log'}\n",
      "84:{'source': '/Library/Github/RI-HEVNAA/logs/R_HCPU.log'}\n",
      "85:{'source': '/Library/Github/RI-HEVNAA/logs/R_HCPU.log'}\n",
      "86:{'source': '/Library/Github/RI-HEVNAA/logs/R_HCPU.log'}\n",
      "87:{'source': '/Library/Github/RI-HEVNAA/logs/R_HCPU.log'}\n",
      "88:{'source': '/Library/Github/RI-HEVNAA/logs/R_HCPU.log'}\n",
      "89:{'source': '/Library/Github/RI-HEVNAA/logs/L_HCPU.log'}\n",
      "90:{'source': '/Library/Github/RI-HEVNAA/logs/L_HCPU.log'}\n",
      "91:{'source': '/Library/Github/RI-HEVNAA/logs/L_HCPU.log'}\n",
      "92:{'source': '/Library/Github/RI-HEVNAA/logs/L_HCPU.log'}\n",
      "93:{'source': '/Library/Github/RI-HEVNAA/logs/L_HCPU.log'}\n",
      "94:{'source': '/Library/Github/RI-HEVNAA/logs/L_HCPU.log'}\n",
      "95:{'source': '/Library/Github/RI-HEVNAA/logs/L_HCPU.log'}\n",
      "96:{'source': '/Library/Github/RI-HEVNAA/logs/WebMonitoringProcess.log'}\n",
      "97:{'source': '/Library/Github/RI-HEVNAA/logs/execute.log'}\n",
      "98:{'source': '/Library/Github/RI-HEVNAA/logs/Accelerators.log'}\n",
      "99:{'source': '/Library/Github/RI-HEVNAA/logs/Accelerators.log'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import Language\n",
    "def print_texts(texts):\n",
    "    print(f\"Found {len(texts)} texts.\")\n",
    "    i=0\n",
    "    for text in texts:\n",
    "        i = i+1\n",
    "        print(f\"{i}:{text.metadata}\")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(language=Language.PYTHON, \n",
    "                                                               chunk_size=2000, \n",
    "                                                               chunk_overlap=200)\n",
    "markdown_splitter = RecursiveCharacterTextSplitter.from_language(language=Language.MARKDOWN,\n",
    "                                                                    chunk_size=2000,\n",
    "                                                                    chunk_overlap=200)\n",
    "\n",
    "log_splitter = RecursiveCharacterTextSplitter.from_language(language=Language.MARKDOWN,\n",
    "                                                                    chunk_size=2000,\n",
    "                                                                    chunk_overlap=200)\n",
    "                                                            \n",
    "\n",
    "texts = python_splitter.split_documents(python_documents)\n",
    "\n",
    "\n",
    "texts += markdown_splitter.split_documents(markdown_documents)\n",
    "\n",
    "\n",
    "texts += log_splitter.split_documents(log_documents)\n",
    "print_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "db = Chroma.from_documents(texts, OpenAIEmbeddings(disallowed_special=()))\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\", # Also test \"similarity\"\n",
    "    search_kwargs={\"k\": 8},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "#memory = ConversationSummaryMemory(llm=llm, chat_memory=chat_history)\n",
    "memory = ConversationSummaryMemory(llm=llm,memory_key=\"chat_history\",return_messages=True)\n",
    "#memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"What is RI_HEVNAA?\")\n",
    "memory.chat_memory.add_ai_message(\"Give me a moment to think about that\")\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: Tell me more about RI_HEVNAA\u001b[0m\n",
      "I'm sorry, but I'm unable to provide information on \"RI_HEVNAA\" as it doesn't seem to correspond to any known entity, concept, or topic in my database. Could you please provide more context or check if there's a typo in your message?\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Tell me more about RI_HEVNAA',\n",
       " 'chat_history': [HumanMessage(content='Tell me more about RI_HEVNAA', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='I\\'m sorry, but I\\'m unable to provide information on \"RI_HEVNAA\" as it doesn\\'t seem to correspond to any known entity, concept, or topic in my database. Could you please provide more context or check if there\\'s a typo in your message?', additional_kwargs={}, example=False)],\n",
       " 'text': 'I\\'m sorry, but I\\'m unable to provide information on \"RI_HEVNAA\" as it doesn\\'t seem to correspond to any known entity, concept, or topic in my database. Could you please provide more context or check if there\\'s a typo in your message?'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "#qa.run(\"Tell me more about RI_HEVNAA\")\n",
    "\n",
    "# Prompt \n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a nice chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        # The `variable_name` here is what must align with memory\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\n",
    "conversation({\"question\": \"Tell me more about RI_HEVNAA\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "question = None\n",
    "answer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'messages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmessages\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'messages' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"{messages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Tell me about RI-HEVNAA', additional_kwargs={}, example=False), AIMessage(content=\"RI-HEVNAA, which stands for Real-time Interrupt-driven Hemispheric Emulated von Neumann Agent Architecture, is an advanced chatbot architecture designed to replicate the structure and functionality of the human brain. The architecture draws inspiration from principles of biomimicry and von Neumann's computational model, and it provides a comprehensive framework for building sophisticated and human-like chatbot systems.\\n\\nThe RI-HEVNAA architecture comprises several key components. These include SuperUnits, each equipped with an Agent Central Processing Unit (A-CPU) and specialized Accelerators. SuperUnits include the Agent SuperUnit (A_SU), Left Hemisphere SuperUnit (LH_SU), and Right Hemisphere SuperUnit (RH_SU), each dedicated to different tasks similar to the human brain's division of labor.\\n\\nThe architecture also features real-time interaction with hardware components, enabling seamless coordination and control of physical devices. By integrating with hardware modules such as servos, LiDAR modules, and Inertial Measurement Units (IMUs), the architecture can perform actions based on sensor inputs and spatial coordination tasks.\\n\\nRI-HEVNAA is designed to be scalable and extensible, allowing for the seamless addition of new SuperUnits, Accelerators, and Tasks, and integration with external systems and tools to enhance functionality. It also incorporates feedback mechanisms for continuous improvement.\\n\\nThe architecture is showcased in various examples, demonstrating its capabilities in language processing, hardware interaction, and natural language understanding.\", additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "if question is None:\n",
    "    print(\"Ask a question first!\") \n",
    "else:\n",
    "    messages.append(HumanMessage(content=question))\n",
    "    messages.append(AIMessage(content=answer))\n",
    "    print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import (\n",
    "    StuffDocumentsChain, LLMChain, ConversationalRetrievalChain\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "combine_docs_chain = StuffDocumentsChain()\n",
    "vectorstore = \n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# This controls how the standalone question is generated.\n",
    "# Should take `chat_history` and `question` as input variables.\n",
    "template = (\n",
    "    \"Combine the chat history and follow up question into \"\n",
    "    \"a standalone question. Chat History: {chat_history}\"\n",
    "    \"Follow up question: {question}\"\n",
    ")\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "llm = OpenAI()\n",
    "question_generator_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain = ConversationalRetrievalChain(\n",
    "    combine_docs_chain=combine_docs_chain,\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'messages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm(messages)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'messages' is not defined"
     ]
    }
   ],
   "source": [
    "llm(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.chat_memory = messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Tell me about RI-HEVNAA', additional_kwargs={}, example=False), AIMessage(content=\"RI-HEVNAA, which stands for Real-time Interrupt-driven Hemispheric Emulated von Neumann Agent Architecture, is an advanced chatbot architecture designed to replicate the structure and functionality of the human brain. The architecture draws inspiration from principles of biomimicry and von Neumann's computational model, and it provides a comprehensive framework for building sophisticated and human-like chatbot systems.\\n\\nThe RI-HEVNAA architecture comprises several key components. These include SuperUnits, each equipped with an Agent Central Processing Unit (A-CPU) and specialized Accelerators. SuperUnits include the Agent SuperUnit (A_SU), Left Hemisphere SuperUnit (LH_SU), and Right Hemisphere SuperUnit (RH_SU), each dedicated to different tasks similar to the human brain's division of labor.\\n\\nThe architecture also features real-time interaction with hardware components, enabling seamless coordination and control of physical devices. By integrating with hardware modules such as servos, LiDAR modules, and Inertial Measurement Units (IMUs), the architecture can perform actions based on sensor inputs and spatial coordination tasks.\\n\\nRI-HEVNAA is designed to be scalable and extensible, allowing for the seamless addition of new SuperUnits, Accelerators, and Tasks, and integration with external systems and tools to enhance functionality. It also incorporates feedback mechanisms for continuous improvement.\\n\\nThe architecture is showcased in various examples, demonstrating its capabilities in language processing, hardware interaction, and natural language understanding.\", additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "# print & render newline characters\n",
    "print(memory.chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat history:\n",
      "messages=[HumanMessage(content='What is RI_HEVNAA?', additional_kwargs={}, example=False), AIMessage(content='Give me a moment to think about that', additional_kwargs={}, example=False)]\n",
      "Question:\n",
      "Okay, please tell me more\n",
      "Can you provide more information?Sure, can you please specify what information you're interested in? Are you looking for more information about Dotenv, the language processing scenario and RI-HEVNAA architecture, or the code snippet at the end?The human asks the AI for more information. The AI asks the human to specify whether they want more information about Dotenv, the language processing scenario and RI-HEVNAA architecture, or the code snippet at the end.Sure, can you please specify what information you're interested in? Are you looking for more information about Dotenv, the language processing scenario and RI-HEVNAA architecture, or the code snippet at the end?\n"
     ]
    }
   ],
   "source": [
    "#question = input(\"Ask a question: \")\n",
    "question = \"Okay, please tell me more\"\n",
    "chat_history = memory.chat_memory\n",
    "print(f\"Chat history:\\n{chat_history}\")\n",
    "print(f\"Question:\\n{question}\")\n",
    "\n",
    "result = qa(question)\n",
    "\n",
    "\n",
    "answer = result['answer']\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
